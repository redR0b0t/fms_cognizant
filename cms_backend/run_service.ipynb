{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !chmod 777 install_reqs.sh\n",
    "# !./install_reqs.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ASR\n",
    "from models.complaint_model import ComplaintModel\n",
    "import torch\n",
    "from transformers import AutoModelForCTC, AutoProcessor\n",
    "import torchaudio.functional as F\n",
    "import pyctcdecode\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, pipeline\n",
    "import soundfile\n",
    "import torchaudio\n",
    "import requests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting backend service\n"
     ]
    }
   ],
   "source": [
    "print(\"starting backend service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASR Service\n",
    "\n",
    "\n",
    "DEVICE_ID = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "asr_langs={'hindi':'hi'}\n",
    "asr_model_ids={'hindi':\"ai4bharat/indicwav2vec-hindi\"}\n",
    "asr_models={}\n",
    "asr_processors = {}\n",
    "\n",
    "def load_asr_models():\n",
    "    for lang in asr_langs:\n",
    "        asr_models[lang]=AutoModelForCTC.from_pretrained(asr_model_ids[lang]).to(DEVICE_ID)\n",
    "        asr_processors[lang]=Wav2Vec2Processor.from_pretrained(asr_model_ids[lang])\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def load_audio_from_url(url):\n",
    "    local_filename = url.split('/')[-1].split(\"%2F\")[1].split(\"?\")[0]\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    file_path=local_filename\n",
    "    waveform, sample_rate = torchaudio.load(file_path)\n",
    "    num_channels, _ = waveform.shape\n",
    "    if num_channels == 1:\n",
    "        return waveform[0], sample_rate\n",
    "    else:\n",
    "        raise ValueError(\"Waveform with more than 1 channels are not supported.\")    \n",
    "\n",
    "def convert_stt(complaint:ComplaintModel):\n",
    "    if complaint.lang not in asr_models:\n",
    "        print(f\"---------loading asr model for {complaint.lang}----------\")\n",
    "        asr_models[complaint.lang]=AutoModelForCTC.from_pretrained(asr_model_ids[complaint.lang]).to(DEVICE_ID)\n",
    "        asr_processors[complaint.lang]=Wav2Vec2Processor.from_pretrained(asr_model_ids[complaint.lang])\n",
    "    #Load from url\n",
    "    waveform, sample_rate = load_audio_from_url(complaint.audioURL)\n",
    "    resampled_audio = torchaudio.functional.resample(waveform, sample_rate, 16000)\n",
    "    input_values = asr_processors[complaint.lang](resampled_audio, return_tensors=\"pt\").input_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = asr_models[complaint.lang](input_values.to(DEVICE_ID)).logits.cpu()\n",
    "    \n",
    "    prediction_ids = torch.argmax(logits, dim=-1)\n",
    "    output_str = asr_processors[complaint.lang].batch_decode(prediction_ids)[0]\n",
    "    print(f\"Greedy Decoding: {output_str}\")\n",
    "    return output_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5f8a87982dcb10536c03fdd4afd4637/.local/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Translation Service\n",
    "# code for translation\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
    "import models.complaint_model\n",
    "\n",
    "trans_langs={\"hindi\":'hin_Deva'}\n",
    "trans_tokenizer = IndicTransTokenizer(direction=\"indic-en\")\n",
    "trans_ip = IndicProcessor(inference=True)\n",
    "trans_model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indictrans2-indic-en-dist-200M\", trust_remote_code=True)\n",
    "\n",
    "def translate(complaint):\n",
    "    input=[complaint.complaintText]\n",
    "        \n",
    "    batch = trans_ip.preprocess_batch(input, src_lang=trans_langs[complaint.lang], tgt_lang=\"eng_Latn\")\n",
    "    batch = trans_tokenizer(batch, src=True, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = trans_model.generate(**batch, num_beams=5, num_return_sequences=1, max_length=256)\n",
    "\n",
    "    outputs = trans_tokenizer.batch_decode(outputs, src=False)\n",
    "    outputs = trans_ip.postprocess_batch(outputs, lang=trans_langs[complaint.lang])\n",
    "    print(outputs)\n",
    "    return outputs[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90d0c5ee1ea4ed8bdeea5a3bffe5f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u5f8a87982dcb10536c03fdd4afd4637/.local/lib/python3.9/site-packages/accelerate/utils/imports.py:306: UserWarning: Intel Extension for PyTorch 2.0 needs to work with PyTorch 2.0.*, but PyTorch 2.1.2 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Finetuned ft5 response/listener function\n",
    "from peft import AutoPeftModelForSeq2SeqLM,PeftModel\n",
    "from transformers import AutoTokenizer,AutoConfig,T5ForConditionalGeneration,AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "from finetune.instruction import instruction\n",
    "\n",
    "# wd_path='E:\\ETC\\Progress\\Projects\\web_app\\mh_bhasha3\\cms_backend'\n",
    "wd_path='~/mh_bhasha3/cms_backend'\n",
    "\n",
    "use_ft_model=True\n",
    "base_model_path=\"google/flan-t5-xl\"\n",
    "\n",
    "if use_ft_model:\n",
    "    ft5_tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "    # from tokenizers import AddedToken\n",
    "    # stokens_v3=[\"{\",\"}\",\"<\",\"`\",\"\\\\\"]\n",
    "    # stokens=stokens_v3\n",
    "    # for st in stokens:\n",
    "    #     ft5_tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "    \n",
    "    lcp_path='./finetune/ft_models/flan-t5-xl-mt5-v1/checkpoint-22900'\n",
    "    model_path=lcp_path\n",
    "    # ft5_model = AutoPeftModelForSeq2SeqLM(model,)\n",
    "    # Load base model\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained( base_model_path,)\n",
    "    base_model.resize_token_embeddings(len(ft5_tokenizer))\n",
    "     # Load PEFT model\n",
    "    ft5_model = PeftModel.from_pretrained(model=base_model, model_id =lcp_path,)\n",
    "    \n",
    " \n",
    "\n",
    "    \n",
    "else:\n",
    "    model_path=base_model_path\n",
    "    ft5_model = AutoModelForSeq2SeqLM.from_pretrained(model_path, )\n",
    "    ft5_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def categorize(complaint):\n",
    "    print(\"-------------generating response-----------------\")\n",
    "    context=complaint.complaintText\n",
    "    # context=context.replace('\\n',' \\\\n ')\n",
    "    # context=context.replace('\\t',' \\\\t ')\n",
    "\n",
    "    input=f'complaint:{context}'\n",
    "    # prompts=[[input,instruction]]\n",
    "    prompts=[[f'Input:\\n{input}\\n\\n',f'Instruction:\\n{instruction}',]]\n",
    "    \n",
    "    res=[]\n",
    "    input_ids = ft5_tokenizer(prompts, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "    start_time = time.time()\n",
    "    outputs = ft5_model.generate(input_ids=input_ids, do_sample=True, max_length=150)\n",
    "    pt=time.time() - start_time\n",
    "    print(f\"--------------time taken by model for generating response={pt} seconds\")\n",
    "\n",
    "    res+=ft5_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return  { 'output': f'{res[0]}' }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input=\"complaint:my train was late, my pnr is 2345\"\n",
    "\n",
    "# from finetune.instruction import instruction\n",
    "# # categories=['Train','station','suggestion','enquiry','staff']\n",
    "# # instruction=f\"\"\"Identify the following from the complaint:\n",
    "# # 1)category of the complaint from the following categories:{categories.__str__()}.\n",
    "# # 2)a priority for the complaint.\n",
    "# # 3)extract attributes from the complaint.\n",
    "# # 4)identify sentiment from the complaint.\n",
    "# # return the output in format: tags:[],priority:[],attributes:[],sentiment:[]\n",
    "# # \"\"\"\n",
    "# prompts=[[input,instruction]]\n",
    "# prompts=[[f'Input:\\n{input}\\n\\n',f'Instruction:\\n{instruction}',]]\n",
    "\n",
    "# res=[]\n",
    "# input_ids = ft5_tokenizer(prompts, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "# start_time = time.time()\n",
    "# outputs = ft5_model.generate(input_ids=input_ids, do_sample=True, max_length=150)\n",
    "# pt=time.time() - start_time\n",
    "# print(f\"--------------time taken by model for generating response={pt} seconds\")\n",
    "\n",
    "# res+=ft5_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listener function\n",
    "from models.complaint_model import ComplaintModel\n",
    "# from cms_backend.utils.ft5 import categorize\n",
    "# from cms_backend.utils.indictrans2 import translate\n",
    "# from cms_backend.utils.indicwav2vec import convert_stt\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "import datetime\n",
    "import json\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from pandas import Timestamp\n",
    "\n",
    "\n",
    "\n",
    "def listen_msgs():\n",
    "    coll_name='mh_bhasha3'\n",
    "    user_uid='mh_bhasha3_user'\n",
    "        \n",
    "    # Use a service account.\n",
    "    cred = credentials.Certificate(f'../keys/sa.json')\n",
    "    if not firebase_admin._apps:\n",
    "        app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "    db = firestore.client()\n",
    "    \n",
    "    # Create an Event for notifying main thread.\n",
    "    callback_done = threading.Event()\n",
    "\n",
    "    # Create a callback on_snapshot function to capture changes\n",
    "    def on_snapshot(doc_snapshot, changes, read_time):\n",
    "        for doc in doc_snapshot:\n",
    "            print(f\"Received document snapshot: {doc.id}\")\n",
    "            print(doc.to_dict())\n",
    "            complaint=ComplaintModel.from_dict(doc.to_dict())\n",
    "            complaint.lang=complaint.lang.lower()\n",
    "            # complaint.complaintText=complaint.complaintText.toString()\n",
    "            # data=doc.to_dict()\n",
    "            if complaint.audioURL!='':\n",
    "                complaint.complaintText=convert_stt(complaint=complaint)\n",
    "            if complaint.lang!='english':\n",
    "                complaint.complaintText=translate(complaint=complaint)\n",
    "\n",
    "            pred_res=categorize(complaint)\n",
    "            # pred_res={'output':\"model response\"}\n",
    "\n",
    "            complaint.senderId='backend@red'\n",
    "            complaint.output=pred_res['output']\n",
    "            # data['priority']=pred_res['output'].split(':')[-1]\n",
    "            complaint.ots=datetime.datetime.utcnow()\n",
    "            print(f'sending response: '+complaint.output)\n",
    "            # doc_id=str(round(time.time() * 1000))\n",
    "            doc_id=complaint.id\n",
    "            db.collection(coll_name).document(user_uid).collection('pComplaints').document(doc_id).set(complaint.__dict__)\n",
    "            print(f\"----------sent----------------with id: {doc_id} \")\n",
    "\n",
    "        callback_done.set()\n",
    "\n",
    "    doc_ref = db.collection(coll_name).document(user_uid).collection('rComplaints').document(\"complaint\")\n",
    "\n",
    "    # Watch the document\n",
    "    doc_watch = doc_ref.on_snapshot(on_snapshot)\n",
    "    print(\"listening for messages...\",)\n",
    "    \n",
    "    \n",
    "\n",
    "    while True:\n",
    "        print('', end='', flush=True)\n",
    "        time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening for messages...\n",
      "Received document snapshot: complaint\n",
      "{'audioURL': '', 'ots': None, 'id': '1712418185632', 'complaintText': 'my train with pnr 12345 got late', 'senderId': 'mhs@red', 'lang': 'Hindi', 'output': '', 'timestamp': DatetimeWithNanoseconds(2024, 4, 6, 15, 43, 5, 632000, tzinfo=datetime.timezone.utc)}\n",
      "['my train with pnr 12345 got late']\n",
      "-------------generating response-----------------\n",
      "--------------time taken by model for generating response=38.16107392311096 seconds\n",
      "sending response: tags:['train'],priority:['2'],attributes:['pnr=12345'],sentiment:['negative']\n",
      "----------sent----------------with id: 1712418185632 \n",
      "Received document snapshot: complaint\n",
      "{'audioURL': '', 'ots': None, 'id': '1712418488261', 'complaintText': 'my train with pnr 568 was late', 'senderId': 'mhs@red', 'lang': 'Hindi', 'timestamp': DatetimeWithNanoseconds(2024, 4, 6, 15, 48, 8, 261000, tzinfo=datetime.timezone.utc), 'output': ''}\n",
      "['my train with pnr 568 was late']\n",
      "-------------generating response-----------------\n",
      "--------------time taken by model for generating response=55.06599187850952 seconds\n",
      "sending response: tags:['train'],priority:['2'],attributes:['pnr-568'],sentiment:['negative']\n",
      "----------sent----------------with id: 1712418488261 \n",
      "Received document snapshot: complaint\n",
      "{'audioURL': '', 'ots': None, 'complaintText': 'my train with pnr 568 was late', 'id': '1712418720463', 'senderId': 'mhs@red', 'lang': 'English', 'timestamp': DatetimeWithNanoseconds(2024, 4, 6, 15, 52, 0, 463000, tzinfo=datetime.timezone.utc), 'output': ''}\n",
      "-------------generating response-----------------\n",
      "--------------time taken by model for generating response=34.90666341781616 seconds\n",
      "sending response: tags:['train'],priority:['2'],attributes:['pnr-568'],sentiment:['negative']\n",
      "----------sent----------------with id: 1712418720463 \n",
      "Received document snapshot: complaint\n",
      "{'ots': None, 'audioURL': '', 'complaintText': 'my train got late by 5 hours', 'id': '1712420879057', 'senderId': 'mhs@red', 'lang': 'English', 'output': '', 'timestamp': DatetimeWithNanoseconds(2024, 4, 6, 16, 27, 59, 59000, tzinfo=datetime.timezone.utc)}\n",
      "-------------generating response-----------------\n",
      "--------------time taken by model for generating response=34.56542110443115 seconds\n",
      "sending response: tags:['train'],priority:['1'],attributes:['train==5'],sentiment:['negative']\n",
      "----------sent----------------with id: 1712420879057 \n"
     ]
    }
   ],
   "source": [
    "# calling the listener function\n",
    "try:\n",
    "    listen_msgs()\n",
    "except Exception as e:\n",
    "    print(f'error occured:\\n\\n\\n {e}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soundfile \n",
    "# !pip install cffi -t /home/u5f8a87982dcb10536c03fdd4afd4637/.local/lib/python3.9/site-packages\n",
    "# !pip3 uninstall -y cffi\n",
    "# import soundfile\n",
    "\n",
    "# !pip show sox\n",
    "# !pip install pysoundfile\n",
    "# import soundfile\n",
    "# import cffi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
